{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import json\n",
    "import copy\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile\n",
    "import time\n",
    "import importlib\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "import util_tfrecords\n",
    "import util_signal\n",
    "import util_cochlea\n",
    "import util_network\n",
    "import util_optimize\n",
    "import util_evaluate\n",
    "import util_figures\n",
    "import util_stimuli\n",
    "import util_misc\n",
    "\n",
    "\n",
    "def azim_elev_to_label(azim, elev):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    label = (elev / 10) * 72 + (azim / 5)\n",
    "    return np.array(label).astype(int)\n",
    "\n",
    "\n",
    "def label_to_azim_elev(label):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    elev = np.array((label // 72) * 10)\n",
    "    azim = np.array((label % 72) * 5)\n",
    "    return np.array(azim).astype(float), np.array(elev).astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'cutoff': 4000, 'numtaps': 4097, 'window': ['kaiser', 5.0]}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'cutoff': 4000, 'numtaps': 4097, 'window': ['kaiser', 5.0]}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loaded: saved_models/tf2_model/archFrancl01/ckpt_BEST\n"
     ]
    }
   ],
   "source": [
    "dir_model = 'saved_models/tf2_model/archFrancl01'\n",
    "fn_arch = os.path.join(dir_model, 'arch.json')\n",
    "fn_config = os.path.join(dir_model, 'config.json')\n",
    "fn_ckpt = os.path.join(dir_model, 'ckpt_BEST')\n",
    "\n",
    "with open(fn_arch, 'r') as f:\n",
    "    list_layer_dict = json.load(f)\n",
    "with open(fn_config, 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "\n",
    "def cochlea_model_io_function(x):\n",
    "    \"\"\"\n",
    "    Wrapper function around cochlear model tensorflow graph\n",
    "    \"\"\"\n",
    "    y = x\n",
    "    if CONFIG.get('kwargs_cochlea', {}):\n",
    "        msg = \"expected input with shape [batch, time, channel=2]\"\n",
    "        assert (len(y.shape) == 3) and (y.shape[-1] == 2), msg\n",
    "        # Cochlear model for ear index 0\n",
    "        y0, _ = util_cochlea.cochlea(y[..., 0], **copy.deepcopy(CONFIG['kwargs_cochlea']))\n",
    "        # Cochlear model for ear index 1\n",
    "        y1, _ = util_cochlea.cochlea(y[..., 1], **copy.deepcopy(CONFIG['kwargs_cochlea']))\n",
    "        # Binaural cochlear model representation with shape [batch, freq, time, channel=2]\n",
    "        y = tf.concat([y0[..., tf.newaxis], y1[..., tf.newaxis]], axis=-1)\n",
    "        msg = \"expected cochlear model output with shape [batch, freq, time, channel=2]\"\n",
    "        assert (len(y.shape) == 4) and (y.shape[-1] == 2), msg\n",
    "    return y\n",
    "\n",
    "\n",
    "def network_model_io_function(x):\n",
    "    \"\"\"\n",
    "    Wrapper function around network tensorflow graph\n",
    "    \"\"\"\n",
    "    y = x\n",
    "    y, _ = util_network.build_network(y, list_layer_dict, n_classes_dict=CONFIG['n_classes_dict'])\n",
    "    return y\n",
    "\n",
    "\n",
    "# Build tensorflow Keras model objects (cochlea, network, combined)\n",
    "tf.keras.backend.clear_session()\n",
    "inputs_sound = tf.keras.Input(shape=(48000, 2), batch_size=None, dtype=tf.float32)\n",
    "inputs_coch = tf.keras.Input(shape=(39, 8000, 2), batch_size=None, dtype=tf.float32)\n",
    "cochlea_model = tf.keras.Model(\n",
    "    inputs=inputs_sound,\n",
    "    outputs=cochlea_model_io_function(inputs_sound),\n",
    "    name='cochlea_model')\n",
    "network_model = tf.keras.Model(\n",
    "    inputs=inputs_coch,\n",
    "    outputs=network_model_io_function(inputs_coch),\n",
    "    name='network_model')\n",
    "model = tf.keras.Model(\n",
    "    inputs=inputs_sound,\n",
    "    outputs=network_model(cochlea_model(inputs_sound)))\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "network_model.load_weights(fn_ckpt) # <-- Loading `network_model` weights will effect `model` as well\n",
    "print('Loaded: {}'.format(fn_ckpt))\n",
    "tf.get_logger().setLevel('INFO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 48000, 2)]        0         \n",
      "                                                                 \n",
      " cochlea_model (Functional)  (None, 39, 8000, 2)       0         \n",
      "                                                                 \n",
      " network_model (Functional)  {'label_loc_int': (None,  53956632  \n",
      "                              504)}                              \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53,956,632\n",
      "Trainable params: 53,953,752\n",
      "Non-trainable params: 2,880\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True labels: [296 170 170 224 443  51 306  84 152 260 332 478 498 347 440 429]\n",
      "Pred labels: [296 171 170 244 443  51 306  96 225 260 332 478 499 347 441 428]\n",
      "True azim: [ 40 130 130  40  55 255  90  60  40 220 220 230 330 295  40 345]\n",
      "Pred azim: [ 40 135 130 140  55 255  90 120  45 220 220 230 335 295  45 340]\n",
      "True elev: [40 20 20 30 60  0 40 10 20 30 40 60 60 40 60 50]\n",
      "Pred elev: [40 20 20 30 60  0 40 10 30 30 40 60 60 40 60 50]\n",
      "Correct: [1 0 1 0 1 1 1 0 0 1 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "fn = '/om2/user/msaddler/data_localize/FLDv01/valid/stim_000000-004763.hdf5'\n",
    "with h5py.File(fn, 'r') as f:\n",
    "    sr_hdf5 = f['sr'][0]\n",
    "    sr = 48e3\n",
    "    IDX = slice(100, 116)\n",
    "    y = f['signal'][IDX]    \n",
    "    y = scipy.signal.resample_poly(y, up=sr, down=sr_hdf5, axis=1)\n",
    "    azim = f['foreground_azimuth'][IDX]\n",
    "    elev = f['foreground_elevation'][IDX]\n",
    "    label = azim_elev_to_label(azim, elev)\n",
    "\n",
    "y_out = model(y[:, 22800:22800 + 48000, :])['label_loc_int'].numpy()\n",
    "y_pred = scipy.special.softmax(y_out, axis=-1)\n",
    "label_pred = np.argmax(y_out, axis=-1)\n",
    "azim_pred, elev_pred = label_to_azim_elev(label_pred)\n",
    "\n",
    "print('True labels: {}'.format(label))\n",
    "print('Pred labels: {}'.format(label_pred))\n",
    "print('True azim: {}'.format(azim.astype(int)))\n",
    "print('Pred azim: {}'.format(azim_pred.astype(int)))\n",
    "print('True elev: {}'.format(elev.astype(int)))\n",
    "print('Pred elev: {}'.format(elev_pred.astype(int)))\n",
    "print('Correct: {}'.format((label == label_pred).astype(int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
