{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pdb\n",
    "import json\n",
    "import copy\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile\n",
    "import time\n",
    "import importlib\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.python.training import py_checkpoint_reader\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "import util_tfrecords\n",
    "import util_signal\n",
    "import util_cochlea\n",
    "import util_network\n",
    "import util_optimize\n",
    "import util_evaluate\n",
    "import util_figures\n",
    "import util_stimuli\n",
    "import util_misc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_legacy_checkpoint(model, fn_ckpt, verbose=True):\n",
    "    \"\"\"\n",
    "    Loads weights from Francl & McDermott (2022) tensorflow1\n",
    "    checkpoints into tensorflow2 Keras model objects.\n",
    "    \"\"\"\n",
    "    model_variables = {v.name: v for v in model.variables}\n",
    "    reader = py_checkpoint_reader.NewCheckpointReader(fn_ckpt)\n",
    "    map_ckpt_var_to_shape = reader.get_variable_to_shape_map()\n",
    "    relevant_variables = {}\n",
    "    \n",
    "    for k_ckpt in sorted(map_ckpt_var_to_shape.keys()):\n",
    "        if ('Adam' not in k_ckpt) and (k_ckpt not in ['beta1_power', 'beta2_power']):\n",
    "            k_rel = k_ckpt\n",
    "            if 'norm' in k_rel:\n",
    "                k_rel = k_rel.replace('batch_normalization', 'batch_norm')\n",
    "                k_rel = k_rel.replace('norm/', 'norm_0/')\n",
    "                if 'archFrancl01' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_8', 'norm_fc_intermediate')\n",
    "                elif 'archFrancl02' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_9', 'norm_fc_intermediate')\n",
    "                elif 'archFrancl03' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_10', 'norm_fc_intermediate')\n",
    "                elif 'archFrancl04' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_8', 'norm_fc_intermediate')\n",
    "                elif 'archFrancl05' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_9', 'norm_fc_intermediate')\n",
    "                elif 'archFrancl06' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_7', 'norm_fc_intermediate')\n",
    "                elif 'archFrancl07' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_7', 'norm_fc_intermediate')\n",
    "                elif 'archFrancl08' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_9', 'norm_fc_intermediate')\n",
    "                elif 'archFrancl09' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_9', 'norm_fc_intermediate')\n",
    "                elif 'archFrancl10' in fn_ckpt:\n",
    "                    k_rel = k_rel.replace('norm_4', 'norm_fc_intermediate')\n",
    "                else:\n",
    "                    raise ValueError('NO IDEA HOW TO DEAL WITH THIS ARCHITECTURE')\n",
    "            if 'wb' in k_rel:\n",
    "                tmp = k_rel.split('_')\n",
    "                k_rel = 'conv_{}/bias'.format(tmp[1])\n",
    "            if 'wc' in k_rel:\n",
    "                tmp = k_rel.split('_')\n",
    "                k_rel = 'conv_{}/kernel'.format(tmp[1])\n",
    "            if 'fc' in k_rel:\n",
    "                k_rel = k_rel.replace('conv_fc', 'fc_intermediate')\n",
    "            if 'out' in k_rel:\n",
    "                k_rel = k_rel.replace('conv_out', 'fc_top')\n",
    "            k_rel = k_rel + ':0'\n",
    "            \n",
    "            consumed = False\n",
    "            for v in model.variables:\n",
    "                if k_rel == v.name:\n",
    "                    if not map_ckpt_var_to_shape[k_ckpt] == v.shape:\n",
    "                        print('--> {}:{}    |    {}:{}'.format(v.name, v.shape, k_ckpt, map_ckpt_var_to_shape[k_ckpt]))\n",
    "                    relevant_variables[k_rel] = reader.get_tensor(k_ckpt)\n",
    "                    consumed = True\n",
    "            if (not consumed) and (verbose):\n",
    "                print('IGNORING VARIABLE IN CKPT: {}'.format(k_rel), k_ckpt, map_ckpt_var_to_shape[k_ckpt])\n",
    "    \n",
    "    for v in model.variables:\n",
    "        if v.name in relevant_variables:\n",
    "            assert v.shape == relevant_variables[v.name].shape\n",
    "            assert v.dtype == relevant_variables[v.name].dtype\n",
    "            v.assign(relevant_variables[v.name])\n",
    "        else:\n",
    "            raise ValueError('VARIABLE MISSING FROM CKPT: {} {}'.format(v.name, v.shape))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I organize my models as individual directories. Each model has it's own directory containing:\n",
    "- `config.json`: specifies the cochlear model, all training parameters, and output shape of the network\n",
    "- `arch.json`: specifies the architecture of the neural network\n",
    "- Model checkpoint(s)\n",
    "- Training log(s)\n",
    "- Model evaluation outputs\n",
    "\n",
    "Below is a config dictionary (typically stored as `config.json` in the individual model directories)\n",
    "I've used to train a variant of the Francl & McDermott (2022) model directly on sound waveforms.\n",
    "\n",
    "The important parts are `kwargs_cochlea` and `n_classes_dict`:\n",
    "- `kwargs_cochlea`: specifies the parameters of the cochlear model built in tensorflow\n",
    "- `n_classes_dict`: specifies the output layer's shape and name\n",
    "\"\"\"\n",
    "\n",
    "CONFIG = {\n",
    "    \"kwargs_cochlea\": {\n",
    "        \"config_filterbank\": {\n",
    "            \"max_hi\": 20000.0,\n",
    "            \"min_lo\": 30.0,\n",
    "            \"mode\": \"half_cosine_filterbank\",\n",
    "            \"num_cf\": 39\n",
    "        },\n",
    "        \"config_subband_processing\": {\n",
    "            \"power_compression\": 0.3,\n",
    "            \"rectify\": True\n",
    "        },\n",
    "        \"kwargs_nnresample_poly_filter_input\": {},\n",
    "        \"kwargs_nnresample_poly_filter_output\": {\n",
    "            \"down\": 6,\n",
    "            \"up\": 1,\n",
    "            \"window_length\": 4097\n",
    "        },\n",
    "        \"sr_cochlea\": 48000,\n",
    "        \"sr_input\": 48000,\n",
    "        \"sr_output\": 8000\n",
    "    },\n",
    "    \"kwargs_dataset_from_tfrecords\": {\n",
    "        \"buffer_size_prefetch\": 5,\n",
    "        \"buffer_size_shuffle\": 100,\n",
    "        \"bytes_description\": \"config_bytes_description.pckl\",\n",
    "        \"feature_description\": \"config_feature_description.pckl\",\n",
    "        \"features_to_exclude\": [\n",
    "            \"nervegram_meanrates\"\n",
    "        ]\n",
    "    },\n",
    "    \"kwargs_optimize\": {\n",
    "        \"basename_ckpt_best\": \"ckpt_BEST\",\n",
    "        \"basename_ckpt_epoch\": None,\n",
    "        \"basename_log\": \"log_optimize.csv\",\n",
    "        \"batch_size\": 16,\n",
    "        \"early_stopping_baseline\": None,\n",
    "        \"early_stopping_min_delta\": 0,\n",
    "        \"early_stopping_patience\": None,\n",
    "        \"epochs\": 50,\n",
    "        \"key_inputs\": \"signal\",\n",
    "        \"key_outputs\": \"label_loc_int\",\n",
    "        \"kwargs_loss\": {\n",
    "            \"from_logits\": True,\n",
    "            \"name\": \"SparseCategoricalCrossentropy\",\n",
    "            \"weight\": 1.0\n",
    "        },\n",
    "        \"kwargs_optimizer\": {\n",
    "            \"amsgrad\": False,\n",
    "            \"beta_1\": 0.9,\n",
    "            \"beta_2\": 0.999,\n",
    "            \"epsilon\": 1e-07,\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"name\": \"Adam\"\n",
    "        },\n",
    "        \"monitor_metric\": \"val_accuracy\",\n",
    "        \"monitor_mode\": \"max\",\n",
    "        \"steps_per_epoch\": 10000,\n",
    "        \"validation_steps\": 500\n",
    "    },\n",
    "    \"n_classes_dict\": {\n",
    "        \"label_loc_int\": 504\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl01/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl01/ckpt_BEST\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl02/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl02/ckpt_BEST\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl03/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl03/ckpt_BEST\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl04/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl04/ckpt_BEST\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl05/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl05/ckpt_BEST\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl06/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl06/ckpt_BEST\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl07/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl07/ckpt_BEST\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl08/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl08/ckpt_BEST\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl09/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl09/ckpt_BEST\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "[cochlea] converting audio to subbands using half_cosine_filterbank\n",
      "[cochlea] half-wave rectified subbands\n",
      "[cochlea] resampled subbands from 48000 Hz to 8000 Hz with filter: {'down': 6, 'up': 1, 'window_length': 4097}\n",
      "[cochlea] half-wave rectified resampled subbands\n",
      "[cochlea] applied 0.3 power compression to subbands\n",
      "Loading weights: saved_models/tf1_model/archFrancl10/model.ckpt-100000\n",
      "Loading weights: saved_models/tf2_model/archFrancl10/ckpt_BEST\n"
     ]
    }
   ],
   "source": [
    "tf.get_logger().setLevel('ERROR') # Suppress warnings about variable identifiers not matching\n",
    "\n",
    "list_dir_model = glob.glob('saved_models/tf2_model/archFrancl??')\n",
    "input_shape = (48000, 2)\n",
    "\n",
    "for dir_model in list_dir_model:\n",
    "    fn_arch = os.path.join(dir_model, 'arch.json')\n",
    "    fn_config = os.path.join(dir_model, 'config.json')\n",
    "    fn_ckpt_tf2 = os.path.join(dir_model, 'ckpt_BEST')\n",
    "    fn_ckpt_tf1 = os.path.join(dir_model.replace('tf2_model', 'tf1_model'), 'model.ckpt-100000')\n",
    "    \n",
    "    with open(fn_arch, 'r') as f:\n",
    "        list_layer_dict = json.load(f)\n",
    "    with open(fn_config, 'w') as f:\n",
    "        json.dump(CONFIG, f, sort_keys=True, indent=4)\n",
    "    \n",
    "    def model_io_function(x):\n",
    "        \"\"\"\n",
    "        This functions describes how the model should convert inputs to outputs.\n",
    "        It will be used to build the tensorflow model object.\n",
    "        \"\"\"\n",
    "        y = x\n",
    "        if CONFIG.get('kwargs_cochlea', {}):\n",
    "            msg = \"expected input with shape [batch, time, channel=2]\"\n",
    "            assert (len(y.shape) == 3) and (y.shape[-1] == 2), msg\n",
    "            # Cochlear model for ear index 0\n",
    "            y0, _ = util_cochlea.cochlea(y[..., 0], **copy.deepcopy(CONFIG['kwargs_cochlea']))\n",
    "            # Cochlear model for ear index 1\n",
    "            y1, _ = util_cochlea.cochlea(y[..., 1], **copy.deepcopy(CONFIG['kwargs_cochlea']))\n",
    "            # Binaural cochlear model representation with shape [batch, freq, time, channel=2]\n",
    "            y = tf.concat([y0[..., tf.newaxis], y1[..., tf.newaxis]], axis=-1)\n",
    "            msg = \"expected cochlear model output with shape [batch, freq, time, channel=2]\"\n",
    "            assert (len(y.shape) == 4) and (y.shape[-1] == 2), msg\n",
    "        y, _ = util_network.build_network(y, list_layer_dict, n_classes_dict=CONFIG['n_classes_dict'])\n",
    "        return y\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    inputs = tf.keras.Input(shape=input_shape, batch_size=None, dtype=tf.float32)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=model_io_function(inputs))\n",
    "    \n",
    "    weights_init = {v.name: v.numpy() for v in model.weights}\n",
    "    print('Loading weights: {}'.format(fn_ckpt_tf1))\n",
    "    load_legacy_checkpoint(model, fn_ckpt_tf1) # Load weights from tensorflow1 checkpoint\n",
    "    weights_tf1 = {v.name: v.numpy() for v in model.weights}\n",
    "    print('Loading weights: {}'.format(fn_ckpt_tf2))\n",
    "    model.load_weights(fn_ckpt_tf2) # Load weights from tensorflow2 checkpoint\n",
    "    weights_tf2 = {v.name: v.numpy() for v in model.weights}\n",
    "    \n",
    "    for k in sorted(weights_init.keys()):\n",
    "        tf1_equals_init = np.array_equal(weights_init[k], weights_tf1[k])\n",
    "        tf2_equals_init = np.array_equal(weights_init[k], weights_tf2[k])\n",
    "        tf2_equals_tf1 = np.array_equal(weights_tf2[k], weights_tf1[k])\n",
    "        msg = \"Unexpected checkpoint behavior for variable {} with shape {}\".format(k, weights_init[k].shape)\n",
    "        if tf1_equals_init:\n",
    "            print(msg)\n",
    "        if tf2_equals_init:\n",
    "            print(msg)\n",
    "        if not tf2_equals_tf1:\n",
    "            print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 48000, 2)]   0           []                               \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 48000)       0           ['input_1[0][0]']                \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 48000)       0           ['input_1[0][0]']                \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " sequential (Sequential)        (None, 39, 8000)     0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, 39, 8000)     0           ['tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2 (Sl  (None, 39, 8000, 1)  0          ['sequential[0][0]']             \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3 (Sl  (None, 39, 8000, 1)  0          ['sequential_1[0][0]']           \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 39, 8000, 2)  0           ['tf.__operators__.getitem_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'tf.__operators__.getitem_3[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad (TFOpLambda)  (None, 40, 8000, 2)  0           ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " conv_0 (Conv2D)                (None, 39, 7997, 32  544         ['tf.compat.v1.pad[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool_0 (MaxPooling2D)          (None, 19, 3998, 32  0           ['conv_0[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu_0 (ReLU)                  (None, 19, 3998, 32  0           ['pool_0[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_0 (BatchNormalizati  (None, 19, 3998, 32  128        ['relu_0[0][0]']                 \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_1 (TFOpLambda  (None, 20, 3998, 32  0          ['batch_norm_0[0][0]']           \n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)                (None, 19, 3995, 32  8224        ['tf.compat.v1.pad_1[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool_1 (MaxPooling2D)          (None, 19, 998, 32)  0           ['conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " relu_1 (ReLU)                  (None, 19, 998, 32)  0           ['pool_1[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_1 (BatchNormalizati  (None, 19, 998, 32)  128        ['relu_1[0][0]']                 \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_2 (TFOpLambda  (None, 21, 998, 32)  0          ['batch_norm_1[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)                (None, 19, 983, 64)  98368       ['tf.compat.v1.pad_2[0][0]']     \n",
      "                                                                                                  \n",
      " pool_2 (MaxPooling2D)          (None, 19, 491, 64)  0           ['conv_2[0][0]']                 \n",
      "                                                                                                  \n",
      " relu_2 (ReLU)                  (None, 19, 491, 64)  0           ['pool_2[0][0]']                 \n",
      "                                                                                                  \n",
      " batch_norm_2 (BatchNormalizati  (None, 19, 491, 64)  256        ['relu_2[0][0]']                 \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " tf.compat.v1.pad_3 (TFOpLambda  (None, 19, 491, 64)  0          ['batch_norm_2[0][0]']           \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv_3 (Conv2D)                (None, 19, 490, 128  16512       ['tf.compat.v1.pad_3[0][0]']     \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool_3 (MaxPooling2D)          (None, 19, 245, 128  0           ['conv_3[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " relu_3 (ReLU)                  (None, 19, 245, 128  0           ['pool_3[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_norm_3 (BatchNormalizati  (None, 19, 245, 128  512        ['relu_3[0][0]']                 \n",
      " on)                            )                                                                 \n",
      "                                                                                                  \n",
      " flatten_end_conv (Flatten)     (None, 595840)       0           ['batch_norm_3[0][0]']           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " fc_intermediate (Dense)        (None, 512)          305070592   ['flatten_end_conv[0][0]']       \n",
      "                                                                                                  \n",
      " relu_fc_intermediate (ReLU)    (None, 512)          0           ['fc_intermediate[0][0]']        \n",
      "                                                                                                  \n",
      " batch_norm_fc_intermediate (Ba  (None, 512)         2048        ['relu_fc_intermediate[0][0]']   \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['batch_norm_fc_intermediate[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      " fc_top (Dense)                 (None, 504)          258552      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 305,455,864\n",
      "Trainable params: 305,454,328\n",
      "Non-trainable params: 1,536\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
